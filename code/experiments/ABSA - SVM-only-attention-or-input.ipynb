{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import feature_extraction, model_selection, metrics\n",
    "import numpy as np\n",
    "import string\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable eager execution since this code is experimental\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = str.maketrans('/', ' ', '!\"#$%&\\'()*+,-.:;<=>?@[\\\\]^_`{|}~' + \"0123456789\")\n",
    "table2 = str.maketrans('/', ' ')\n",
    "stopWords = []\n",
    "dataset = []\n",
    "maxSentLen = 0\n",
    "avgSentLen = 0\n",
    "missingVectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as file:\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        stopWords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text, aspectTerm=None):\n",
    "    text = text.replace(\"[comma]\", \"\")\n",
    "    gw = lambda w: w.lower() if w in aspectTerm else w.translate(table).lower()\n",
    "    if aspectTerm:\n",
    "        text = [gw(word) for word in text.split() \n",
    "                if len(word) > 1 and (word in aspectTerm or word.translate(table).lower() not in stopWords)]        \n",
    "    else:\n",
    "        text = [word.lower() for word in text.translate(table2).split() if len(word) > 1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should $numbers be removed ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 0\n",
    "ll = []\n",
    "with open('data-2_train.csv') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        data = line.split(\",\")\n",
    "        data[2] = preprocess(data[2])\n",
    "        data[1] = preprocess(data[1], data[2])\n",
    "        data[-1] = data[-1].strip()\n",
    "        length += len(data[1])\n",
    "        ll.append(len(data[1]))\n",
    "        if len(data[1]) > maxSentLen:\n",
    "            maxSentLen = len(data[1])\n",
    "        dataset.append(data)\n",
    "avgSentLen = length / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 7.829539144919489\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(maxSentLen, avgSentLen)\n",
    "print(sorted(ll)[int(len(ll)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzPWWjjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27749a64470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(ll)), sorted(ll))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSentLen = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weD = 300\n",
    "wvD = weD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, label):\n",
    "    clf=LinearSVC(multi_class='crammer_singer',random_state=0)\n",
    "    \n",
    "    preds = model_selection.cross_val_predict(clf, data, label, cv=10)\n",
    "    accScore = metrics.accuracy_score(label,preds)\n",
    "    labels = [-1, 0, 1]\n",
    "    precision = metrics.precision_score(label,preds,average=None,labels=labels)\n",
    "    recall = metrics.recall_score(label,preds,average=None,labels=labels)\n",
    "    f1Score = metrics.f1_score(label,preds,average=None,labels=labels)\n",
    "    print(\"\\nOverall Acurracy - SVM: \",accScore,\"\\n\")\n",
    "    for i in range(len(labels)):\n",
    "        print(\"Precision of %s class: %f\" %(labels[i],precision[i]))\n",
    "        print(\"Recall of %s class: %f\" %(labels[i],recall[i]))\n",
    "        print(\"F1-Score of %s class: %f\" %(labels[i],f1Score[i]),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = []\n",
    "y = []\n",
    "yForSk = []\n",
    "flag = \"input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data1 = []\n",
    "    meanAspVec = None\n",
    "    \n",
    "    #if more than one word in aspect term, take mean\n",
    "    mean = np.zeros((weD, 1))\n",
    "    for w in data[2]:\n",
    "        twv = None\n",
    "        try:\n",
    "            if w in missingVectors:\n",
    "                twv = missingVectors[w]\n",
    "            else:\n",
    "                twv = word2vec[w].reshape(weD, 1)\n",
    "        except KeyError:\n",
    "            twv = np.random.normal(size=(weD, 1))/math.sqrt(weD+1)\n",
    "            missingVectors[w] = twv\n",
    "        mean += twv\n",
    "    meanAspVec = mean/len(data[2])\n",
    "    \n",
    "    E = []\n",
    "    \n",
    "#     for wv in data1:\n",
    "#         E.append(np.dot(wv.T, meanAspVec)/(np.linalg.norm(wv)) * np.linalg.norm(meanAspVec))\n",
    "    \n",
    "#     E = np.array(E).reshape(300, 1)\n",
    "#     A = np.exp(E) / np.sum(np.exp(E))\n",
    "\n",
    "    for w in data[1]:\n",
    "        twv = None\n",
    "        try:\n",
    "            if w in missingVectors:\n",
    "                twv = missingVectors[w]\n",
    "            else:\n",
    "                twv = word2vec[w].reshape(weD, 1)\n",
    "        except KeyError:\n",
    "            twv = np.random.normal(size=(weD, 1))/math.sqrt(weD+1)\n",
    "            missingVectors[w] = twv\n",
    "        E.append(np.dot(twv.T, meanAspVec) / (np.linalg.norm(twv) * np.linalg.norm(meanAspVec)))\n",
    "\n",
    "    A = np.exp(E) / np.sum(np.exp(E)) # softmax\n",
    "\n",
    "    for i, w in enumerate(data[1]):\n",
    "        twv = None\n",
    "        if w in missingVectors:\n",
    "            twv = missingVectors[w]\n",
    "        else:\n",
    "            twv = word2vec[w].reshape(weD, 1)\n",
    "        if flag == \"attention\":\n",
    "            data1.append(A[i] * twv)\n",
    "        elif flag == \"input\":\n",
    "            data1.append(twv)\n",
    "\n",
    "#     for w in data[1]:\n",
    "#         twv = None\n",
    "#         try:\n",
    "#             if w in missingVectors:\n",
    "#                 twv = missingVectors[w]\n",
    "#             else:\n",
    "#                 twv = word2vec[w].reshape(300, 1)\n",
    "#         except KeyError:\n",
    "#             twv = np.random.normal(size=(300, 1))/math.sqrt(301)\n",
    "#             missingVectors[w] = twv\n",
    "            \n",
    "#         data1.append(np.vstack((twv, meanAspVec)))\n",
    "    \n",
    "    if len(data1) < maxSentLen:\n",
    "        j = len(data1) + 1\n",
    "        while j <= maxSentLen:\n",
    "            #data1.append(np.vstack((word2vec['#'].reshape(300, 1), meanAspVec)))\n",
    "            #data1.append(np.vstack((np.zeros((300, 1)), meanAspVec)))\n",
    "            data1.append(np.zeros((wvD, 1)))\n",
    "            j += 1\n",
    "    \n",
    "    if len(data1) > maxSentLen:\n",
    "        del data1[maxSentLen:]\n",
    "    \n",
    "    X1.append(np.array([np.mean(data1, axis=0)]).reshape(300,))\n",
    "    yForSk.append(data[-1])\n",
    "    if data[-1] == '-1':\n",
    "        y.append(np.array([[0.0, 0.0, 1.0]]))\n",
    "    elif data[-1] == '0':\n",
    "        y.append(np.array([[0.0, 1.0, 0.0]]))\n",
    "    elif data[-1] == '1':\n",
    "        y.append(np.array([[1.0, 0.0, 0.0]]))\n",
    "\n",
    "X1 = np.array(X1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 300)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 1, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yForSk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Acurracy - SVM:  0.6785119378123264 \n",
      "\n",
      "Precision of -1 class: 0.582665\n",
      "Recall of -1 class: 0.450932\n",
      "F1-Score of -1 class: 0.508403 \n",
      "\n",
      "Precision of 0 class: 0.477778\n",
      "Recall of 0 class: 0.135861\n",
      "F1-Score of 0 class: 0.211562 \n",
      "\n",
      "Precision of 1 class: 0.712755\n",
      "Recall of 1 class: 0.921904\n",
      "F1-Score of 1 class: 0.803949 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    }
   ],
   "source": [
    "train(X1, yForSk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 0\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 83ms/step - loss: 10.2660 - acc: 0.5958\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 78ms/step - loss: 10.1070 - acc: 0.5983\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 79ms/step - loss: 10.0637 - acc: 0.5983\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 10.0308 - acc: 0.5983\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 9s 87ms/step - loss: 10.0021 - acc: 0.5983\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  64,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([362], dtype=int64))\n",
      "accuracy= 0.5994475138121547 precision= [0.59944751 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.74956822 0.         0.        ]\n",
      "Fold - 1\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.2972 - acc: 0.5965\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.1187 - acc: 0.5983\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0486 - acc: 0.5983\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 9s 86ms/step - loss: 10.0280 - acc: 0.5983\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 79ms/step - loss: 9.9944 - acc: 0.5983\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  64,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([362], dtype=int64))\n",
      "accuracy= 0.5994475138121547 precision= [0.59944751 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.74956822 0.         0.        ]\n",
      "Fold - 2\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 10.3393 - acc: 0.5980\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 88ms/step - loss: 10.1334 - acc: 0.5983\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0998 - acc: 0.5983\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0237 - acc: 0.5983\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 9s 84ms/step - loss: 10.0443 - acc: 0.5983\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  64,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([362], dtype=int64))\n",
      "accuracy= 0.5994475138121547 precision= [0.59944751 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.74956822 0.         0.        ]\n",
      "Fold - 3\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 83ms/step - loss: 10.3364 - acc: 0.5981\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 86ms/step - loss: 10.1264 - acc: 0.5996\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 75ms/step - loss: 10.0613 - acc: 0.5996\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 74ms/step - loss: 10.0198 - acc: 0.5996\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 75ms/step - loss: 10.0073 - acc: 0.5996\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  63,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([361], dtype=int64))\n",
      "accuracy= 0.6011080332409973 precision= [0.60110803 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75086505 0.         0.        ]\n",
      "Fold - 4\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 10s 94ms/step - loss: 10.2608 - acc: 0.5946\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 90ms/step - loss: 10.0917 - acc: 0.5995\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 9s 89ms/step - loss: 10.0984 - acc: 0.5995\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0273 - acc: 0.5995\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 9.9902 - acc: 0.5995\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([360], dtype=int64))\n",
      "accuracy= 0.6 precision= [0.6 0.  0. ] recall= [1. 0. 0.] F1 Score= [0.75 0.   0.  ]\n",
      "Fold - 5\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.3260 - acc: 0.5945\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.1077 - acc: 0.5986\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 9s 83ms/step - loss: 10.0579 - acc: 0.5986\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 10.0355 - acc: 0.5986\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0292 - acc: 0.5986\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 6\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.3108 - acc: 0.5954\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 84ms/step - loss: 10.1129 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 9s 87ms/step - loss: 10.0843 - acc: 0.5992\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0506 - acc: 0.5992\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0477 - acc: 0.5992\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 7\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 89ms/step - loss: 10.3360 - acc: 0.5979\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.1132 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0837 - acc: 0.5992\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0273 - acc: 0.5992\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0337 - acc: 0.5992\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 8\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 85ms/step - loss: 10.3262 - acc: 0.5973\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.1042 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0688 - acc: 0.5992\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0355 - acc: 0.5992\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0145 - acc: 0.5992\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 9\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 83ms/step - loss: 10.4012 - acc: 0.5915\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.1259 - acc: 0.5980\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0948 - acc: 0.5980\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0562 - acc: 0.5980\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0128 - acc: 0.5980\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# accuracies = []\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# f1s = []\n",
    "\n",
    "# for index, (train_ind, test_ind) in enumerate(kf.split(X1, yForSk)):\n",
    "#     print(\"Fold -\", index)\n",
    "#     xtrain, xtest = X1[train_ind], X1[test_ind]\n",
    "#     ytrain, ytest = y[train_ind], y[test_ind]\n",
    "    \n",
    "#     model = train(xtrain, ytrain)\n",
    "    \n",
    "#     predictions = model.predict(xtest)\n",
    "    \n",
    "#     y_pred = tf.argmax(predictions, dimension=1)\n",
    "#     y_test = tf.argmax(ytest.reshape(len(ytest), 3), dimension=1)\n",
    "    \n",
    "#     print(\"Labels=\", np.unique(y_test, return_counts=True))\n",
    "#     print(\"Predictions=\", np.unique(y_pred, return_counts=True))\n",
    "    \n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     numer = np.diag(cm)\n",
    "#     numer = numer.astype(np.float64)\n",
    "#     deno = np.sum(cm, axis = 1, dtype=np.float64)\n",
    "#     recall = np.divide(numer, deno, out=np.zeros_like(numer), where=deno!=0)\n",
    "#     deno = np.sum(cm, axis = 0, dtype=np.float64)\n",
    "#     precision = np.divide(numer, deno, out=np.zeros_like(numer), where=deno!=0)\n",
    "#     #loss, acc = model.evaluate(xtest, ytest)\n",
    "#     nnum = (precision*recall)\n",
    "#     ddeno = (precision+recall)\n",
    "#     f1 = 2*np.divide(nnum, ddeno, out=np.zeros_like(nnum), where=ddeno!=0)\n",
    "#     acc = np.sum(numer)/np.sum(deno)\n",
    "    \n",
    "#     accuracies.append(acc)\n",
    "#     precisions.append(precision)\n",
    "#     recalls.append(recall)\n",
    "#     f1s.append(f1)\n",
    "#     print(\"accuracy=\", acc, \"precision=\", precision, \"recall=\", recall, \"F1 Score=\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Scores:\n",
      "Avg. accuracy= 0.6007807120638463\n",
      "Avg. precision= [0.60078071 0.         0.        ]\n",
      "Avg. recall= [1. 0. 0.]\n",
      "Avg. f1= [0.75060915 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Scores:\")\n",
    "print(\"Avg. accuracy=\", np.sum(accuracies)/len(accuracies))\n",
    "print(\"Avg. precision=\", np.sum(precisions, axis=0)/len(precisions))\n",
    "print(\"Avg. recall=\", np.sum(recalls, axis=0)/len(recalls))\n",
    "print(\"Avg. f1=\", np.sum(f1s, axis=0)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,   0,  78],\n",
       "       [ 59,   0,  33],\n",
       "       [ 83,   0,  91]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.one_hot(tf.argmax(predictions, dimension=1), depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(579), Dimension(3)])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.48437500e-01, -2.67333984e-02,  1.18652344e-01,  7.32421875e-03,\n",
       "        1.42578125e-01,  8.69140625e-02, -1.10351562e-01,  1.30859375e-01,\n",
       "        6.52343750e-01,  3.20312500e-01, -3.71093750e-01,  3.98437500e-01,\n",
       "       -1.03515625e-01, -1.46484375e-01,  2.49023438e-01,  5.31250000e-01,\n",
       "       -1.26953125e-02,  6.83593750e-03, -1.34277344e-02, -5.50781250e-01,\n",
       "        3.93066406e-02, -1.61132812e-01, -1.97265625e-01, -3.46679688e-02,\n",
       "        1.78710938e-01,  4.85839844e-02, -1.96289062e-01,  4.76562500e-01,\n",
       "       -7.37304688e-02, -4.35546875e-01,  2.77099609e-02,  3.86718750e-01,\n",
       "       -1.40625000e-01,  2.42187500e-01, -3.12500000e-01, -3.43750000e-01,\n",
       "        4.88281250e-01, -2.53906250e-01, -9.08203125e-02,  2.19726562e-01,\n",
       "        1.73828125e-01, -1.50390625e-01,  9.27734375e-02, -2.34375000e-02,\n",
       "        2.51953125e-01, -9.03320312e-02, -9.91210938e-02, -1.99218750e-01,\n",
       "        2.83203125e-01, -2.73437500e-01,  1.02539062e-01, -2.08984375e-01,\n",
       "        9.70458984e-03,  3.10546875e-01, -2.46093750e-01, -2.69775391e-02,\n",
       "       -2.65625000e-01,  8.98437500e-02, -3.35937500e-01,  9.71679688e-02,\n",
       "        3.95507812e-02,  7.61718750e-02, -4.78515625e-01, -6.05468750e-02,\n",
       "        7.56835938e-02, -1.50390625e-01,  1.08398438e-01,  4.10156250e-01,\n",
       "        8.93554688e-02,  2.59765625e-01,  9.08203125e-02, -5.07812500e-01,\n",
       "       -5.54199219e-02, -5.54687500e-01, -5.42968750e-01, -4.41406250e-01,\n",
       "       -2.63671875e-01, -4.08203125e-01,  2.57812500e-01,  6.05468750e-02,\n",
       "        4.41406250e-01,  5.83496094e-02, -3.51562500e-01,  3.18359375e-01,\n",
       "        7.56835938e-02,  2.55859375e-01,  2.11914062e-01,  5.58593750e-01,\n",
       "        1.03515625e-01,  4.93164062e-02, -2.28515625e-01, -4.47265625e-01,\n",
       "       -1.10351562e-01, -1.15234375e-01, -5.34057617e-03, -4.02343750e-01,\n",
       "        2.85156250e-01,  4.19921875e-01, -1.94335938e-01,  2.73437500e-01,\n",
       "        1.22558594e-01,  3.02734375e-01,  2.07031250e-01,  1.02050781e-01,\n",
       "       -2.96630859e-02,  3.75976562e-02,  2.06054688e-01,  4.62890625e-01,\n",
       "        1.46484375e-01, -4.55078125e-01, -3.24218750e-01, -2.85156250e-01,\n",
       "        5.50781250e-01,  6.36718750e-01, -2.98828125e-01,  3.10546875e-01,\n",
       "       -3.06640625e-01, -2.85156250e-01,  2.94921875e-01, -3.53515625e-01,\n",
       "        1.36718750e-02, -1.77734375e-01, -2.33398438e-01,  2.02148438e-01,\n",
       "        3.10546875e-01, -1.64794922e-02, -2.18750000e-01,  2.38281250e-01,\n",
       "       -3.61328125e-01, -1.63085938e-01,  3.33984375e-01,  2.24609375e-01,\n",
       "        1.71875000e-01,  2.13623047e-02, -1.76757812e-01,  1.28906250e-01,\n",
       "        1.03515625e-01, -5.79833984e-03, -3.00781250e-01, -1.60156250e-01,\n",
       "        2.28515625e-01, -5.22460938e-02,  9.52148438e-02, -1.87500000e-01,\n",
       "       -3.75000000e-01, -2.69531250e-01,  2.30468750e-01,  7.38281250e-01,\n",
       "        1.16699219e-01, -5.03906250e-01,  6.28906250e-01, -6.12792969e-02,\n",
       "       -1.96289062e-01, -7.37304688e-02,  2.67578125e-01, -3.10546875e-01,\n",
       "        3.37600708e-04, -3.97949219e-02, -2.19726562e-01,  3.94531250e-01,\n",
       "       -2.30468750e-01, -3.80859375e-01, -9.86328125e-02, -2.73437500e-01,\n",
       "        1.09375000e-01, -1.21093750e-01,  9.61914062e-02,  2.39257812e-02,\n",
       "       -4.33593750e-01, -1.27929688e-01, -2.89062500e-01, -1.05957031e-01,\n",
       "       -1.50390625e-01,  4.60937500e-01, -7.77343750e-01,  3.47900391e-03,\n",
       "       -9.81445312e-02, -1.74804688e-01, -3.18908691e-03, -5.78613281e-02,\n",
       "       -2.34375000e-01, -5.68847656e-02, -3.20312500e-01, -5.37109375e-02,\n",
       "       -1.55273438e-01, -2.07031250e-01, -2.28515625e-01,  2.50000000e-01,\n",
       "        8.31604004e-04,  8.05664062e-02, -2.24609375e-01,  1.23046875e-01,\n",
       "       -1.99218750e-01, -2.39257812e-01,  1.21093750e-01,  5.00000000e-01,\n",
       "        5.39062500e-01,  9.64355469e-03,  2.10937500e-01, -3.63281250e-01,\n",
       "        4.51171875e-01,  9.32617188e-02,  1.25000000e-01,  2.04101562e-01,\n",
       "        7.86132812e-02, -1.74804688e-01, -2.47070312e-01, -6.09375000e-01,\n",
       "       -1.46484375e-01,  1.32812500e-01,  4.78515625e-02,  4.06250000e-01,\n",
       "       -3.63281250e-01,  1.11328125e-01, -4.47265625e-01,  4.96093750e-01,\n",
       "        1.92382812e-01, -4.61425781e-02, -3.20312500e-01,  1.27929688e-01,\n",
       "       -2.71484375e-01,  3.63281250e-01,  1.96289062e-01,  1.08886719e-01,\n",
       "       -2.16796875e-01, -7.03125000e-02, -3.88183594e-02,  1.99218750e-01,\n",
       "       -3.19824219e-02, -1.91406250e-01, -9.61914062e-02,  1.06811523e-02,\n",
       "        4.80468750e-01, -4.49218750e-01,  2.47802734e-02, -1.18652344e-01,\n",
       "       -1.36718750e-01, -1.00097656e-01, -2.99072266e-02,  3.98437500e-01,\n",
       "       -5.63964844e-02, -3.45703125e-01, -2.55859375e-01, -4.64843750e-01,\n",
       "       -2.20703125e-01, -2.89062500e-01, -9.42382812e-02,  4.53125000e-01,\n",
       "       -1.30859375e-01,  6.54296875e-02,  1.46484375e-01,  7.34375000e-01,\n",
       "       -1.62109375e-01,  3.26171875e-01, -1.40625000e-01,  4.47265625e-01,\n",
       "        1.09863281e-01, -6.54296875e-02, -9.52148438e-02, -2.08007812e-01,\n",
       "        4.88281250e-01,  5.58593750e-01,  2.08984375e-01, -2.15820312e-01,\n",
       "       -1.54296875e-01, -1.42578125e-01, -1.22558594e-01, -1.07910156e-01,\n",
       "       -4.39453125e-01,  9.52148438e-02, -2.99072266e-02, -2.13867188e-01,\n",
       "        4.16015625e-01, -9.47265625e-02,  5.27343750e-01,  4.31640625e-01,\n",
       "        5.07812500e-01, -2.18750000e-01, -1.12304688e-01,  2.07031250e-01,\n",
       "       -8.15429688e-02,  2.81250000e-01,  2.50000000e-01, -7.51953125e-02,\n",
       "        7.66601562e-02, -2.75390625e-01,  3.94531250e-01,  6.88476562e-02,\n",
       "        4.00390625e-01,  7.26562500e-01, -2.33154297e-02,  1.15722656e-01,\n",
       "       -1.19140625e-01,  6.17675781e-02,  2.94921875e-01, -1.90429688e-01,\n",
       "        6.59179688e-02,  2.01171875e-01,  9.17968750e-02, -4.02832031e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vec['#']#.reshape(300, 1) #numpy array\n",
    "#print(word2vec.similarity('computer', 'laptop'))\n",
    "#np.zeros(300).shape\n",
    "#word2vec.distances(word2vec['computer'], other_words=[\"laptop\"])\n",
    "word2vec[\"###GB\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
