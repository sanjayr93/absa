{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import string\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable eager execution since this code is experimental\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = str.maketrans('/', ' ', '!\"#$%&\\'()*+,-.:;<=>?@[\\\\]^_`{|}~' + \"0123456789\")\n",
    "table2 = str.maketrans('/', ' ')\n",
    "stopWords = []\n",
    "dataset = []\n",
    "maxSentLen = 0\n",
    "avgSentLen = 0\n",
    "missingVectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as file:\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        stopWords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text, aspectTerm=None):\n",
    "    text = text.replace(\"[comma]\", \"\")\n",
    "    gw = lambda w: w.lower() if w in aspectTerm else w.translate(table).lower()\n",
    "    if aspectTerm:\n",
    "        text = [gw(word) for word in text.split() \n",
    "                if len(word) > 1 and (word in aspectTerm or word.translate(table).lower() not in stopWords)]        \n",
    "    else:\n",
    "        text = [word.lower() for word in text.translate(table2).split() if len(word) > 1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should $numbers be removed ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 0\n",
    "ll = []\n",
    "with open('data-2_train.csv') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        data = line.split(\",\")\n",
    "        data[2] = preprocess(data[2])\n",
    "        data[1] = preprocess(data[1], data[2])\n",
    "        data[-1] = data[-1].strip()\n",
    "        length += len(data[1])\n",
    "        ll.append(len(data[1]))\n",
    "        if len(data[1]) > maxSentLen:\n",
    "            maxSentLen = len(data[1])\n",
    "        dataset.append(data)\n",
    "avgSentLen = length / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 7.829539144919489\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(maxSentLen, avgSentLen)\n",
    "print(sorted(ll)[int(len(ll)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzPWWjjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27749a64470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(ll)), sorted(ll))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSentLen = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weD = 300\n",
    "wvD = weD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, label):\n",
    "    inputs = keras.layers.Input(shape=(maxSentLen, wvD, 1))\n",
    "    #print(inputs.shape)\n",
    "\n",
    "    #layer<num>_<filtersize>\n",
    "    conv_layer1_2 = keras.layers.Conv2D(200, (3, wvD), 1, padding='valid', activation=tf.nn.relu)(inputs)\n",
    "    #print(conv_layer1_2.shape)\n",
    "    pool_layer1_2 = keras.layers.MaxPool2D((maxSentLen-3+1, 1), strides=1, padding=\"valid\")(conv_layer1_2)\n",
    "    #print(pool_layer1_2.shape)\n",
    "\n",
    "    conv_layer1_3 = keras.layers.Conv2D(200, (4, wvD), 1, padding='valid', activation=tf.nn.relu)(inputs)\n",
    "    #print(conv_layer1_3.shape)\n",
    "    pool_layer1_3 = keras.layers.MaxPool2D((maxSentLen-4+1, 1), strides=1, padding=\"valid\")(conv_layer1_3)\n",
    "    #print(pool_layer1_3.shape)\n",
    "\n",
    "    conv_layer1_4 = keras.layers.Conv2D(200, (5, wvD), 1, padding='valid', activation=tf.nn.relu)(inputs)\n",
    "    #print(conv_layer1_4.shape)\n",
    "    pool_layer1_4 = keras.layers.MaxPool2D((maxSentLen-5+1, 1), strides=1, padding=\"valid\")(conv_layer1_4)\n",
    "    #print(pool_layer1_4.shape)\n",
    "\n",
    "    layer1 = keras.layers.concatenate([pool_layer1_2, pool_layer1_3, pool_layer1_4], axis=1)\n",
    "    #print(layer1.shape)\n",
    "    layer1 = keras.layers.Flatten()(layer1)\n",
    "    #print(layer1.shape)\n",
    "    \n",
    "    dropout = keras.layers.Dropout(0.5)(layer1)\n",
    "    \n",
    "    out = keras.layers.Dense(3, activation=tf.nn.softmax, kernel_regularizer=keras.regularizers.l2(0.01))(dropout)\n",
    "    #print(out.shape)\n",
    "\n",
    "    nnModel = keras.models.Model(inputs=inputs, outputs=out)\n",
    "    nnModel.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #data = np.array([[word2vec['computer'].reshape(300, 1), word2vec['good'].reshape(300, 1), word2vec['screen'].reshape(300, 1), word2vec['bad'].reshape(300, 1), word2vec['keyboard'].reshape(300, 1)]])\n",
    "    #print(\"data=\", data.shape)\n",
    "    #label = np.array([[1.0, 0.0, 0.0]])\n",
    "    #print(\"label=\", label.shape)\n",
    "    nnModel.fit(data, label, epochs=5)\n",
    "    return nnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = []\n",
    "y = []\n",
    "yForSk = []\n",
    "flag = \"attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data1 = []\n",
    "    meanAspVec = None\n",
    "    \n",
    "    #if more than one word in aspect term, take mean\n",
    "    mean = np.zeros((weD, 1))\n",
    "    for w in data[2]:\n",
    "        twv = None\n",
    "        try:\n",
    "            if w in missingVectors:\n",
    "                twv = missingVectors[w]\n",
    "            else:\n",
    "                twv = word2vec[w].reshape(weD, 1)\n",
    "        except KeyError:\n",
    "            twv = np.random.normal(size=(weD, 1))/math.sqrt(weD+1)\n",
    "            missingVectors[w] = twv\n",
    "        mean += twv\n",
    "    meanAspVec = mean/len(data[2])\n",
    "    \n",
    "    E = []\n",
    "    \n",
    "#     for wv in data1:\n",
    "#         E.append(np.dot(wv.T, meanAspVec)/(np.linalg.norm(wv)) * np.linalg.norm(meanAspVec))\n",
    "    \n",
    "#     E = np.array(E).reshape(300, 1)\n",
    "#     A = np.exp(E) / np.sum(np.exp(E))\n",
    "\n",
    "    for w in data[1]:\n",
    "        twv = None\n",
    "        try:\n",
    "            if w in missingVectors:\n",
    "                twv = missingVectors[w]\n",
    "            else:\n",
    "                twv = word2vec[w].reshape(weD, 1)\n",
    "        except KeyError:\n",
    "            twv = np.random.normal(size=(weD, 1))/math.sqrt(weD+1)\n",
    "            missingVectors[w] = twv\n",
    "        E.append(np.dot(twv.T, meanAspVec) / (np.linalg.norm(twv) * np.linalg.norm(meanAspVec)))\n",
    "\n",
    "    A = np.exp(E) / np.sum(np.exp(E)) # softmax\n",
    "\n",
    "    for i, w in enumerate(data[1]):\n",
    "        twv = None\n",
    "        if w in missingVectors:\n",
    "            twv = missingVectors[w]\n",
    "        else:\n",
    "            twv = word2vec[w].reshape(weD, 1)\n",
    "        if flag == \"attention\":\n",
    "            data1.append(A[i] * twv)\n",
    "        elif flag == \"input\":\n",
    "            data1.append(twv)\n",
    "\n",
    "#     for w in data[1]:\n",
    "#         twv = None\n",
    "#         try:\n",
    "#             if w in missingVectors:\n",
    "#                 twv = missingVectors[w]\n",
    "#             else:\n",
    "#                 twv = word2vec[w].reshape(300, 1)\n",
    "#         except KeyError:\n",
    "#             twv = np.random.normal(size=(300, 1))/math.sqrt(301)\n",
    "#             missingVectors[w] = twv\n",
    "            \n",
    "#         data1.append(np.vstack((twv, meanAspVec)))\n",
    "    \n",
    "    if len(data1) < maxSentLen:\n",
    "        j = len(data1) + 1\n",
    "        while j <= maxSentLen:\n",
    "            #data1.append(np.vstack((word2vec['#'].reshape(300, 1), meanAspVec)))\n",
    "            #data1.append(np.vstack((np.zeros((300, 1)), meanAspVec)))\n",
    "            data1.append(np.zeros((wvD, 1)))\n",
    "            j += 1\n",
    "    \n",
    "    if len(data1) > maxSentLen:\n",
    "        del data1[maxSentLen:]\n",
    "    \n",
    "    X1.append(np.array(data1))\n",
    "    yForSk.append(data[-1])\n",
    "    if data[-1] == '-1':\n",
    "        y.append(np.array([[0.0, 0.0, 1.0]]))\n",
    "    elif data[-1] == '0':\n",
    "        y.append(np.array([[0.0, 1.0, 0.0]]))\n",
    "    elif data[-1] == '1':\n",
    "        y.append(np.array([[1.0, 0.0, 0.0]]))\n",
    "\n",
    "X1 = np.array(X1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 15, 300, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602, 1, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3602,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yForSk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 0\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 83ms/step - loss: 10.2660 - acc: 0.5958\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 78ms/step - loss: 10.1070 - acc: 0.5983\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 79ms/step - loss: 10.0637 - acc: 0.5983\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 10.0308 - acc: 0.5983\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 9s 87ms/step - loss: 10.0021 - acc: 0.5983\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  64,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([362], dtype=int64))\n",
      "accuracy= 0.5994475138121547 precision= [0.59944751 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.74956822 0.         0.        ]\n",
      "Fold - 1\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.2972 - acc: 0.5965\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.1187 - acc: 0.5983\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0486 - acc: 0.5983\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 9s 86ms/step - loss: 10.0280 - acc: 0.5983\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 79ms/step - loss: 9.9944 - acc: 0.5983\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  64,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([362], dtype=int64))\n",
      "accuracy= 0.5994475138121547 precision= [0.59944751 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.74956822 0.         0.        ]\n",
      "Fold - 2\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 10.3393 - acc: 0.5980\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 88ms/step - loss: 10.1334 - acc: 0.5983\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0998 - acc: 0.5983\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0237 - acc: 0.5983\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 9s 84ms/step - loss: 10.0443 - acc: 0.5983\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  64,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([362], dtype=int64))\n",
      "accuracy= 0.5994475138121547 precision= [0.59944751 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.74956822 0.         0.        ]\n",
      "Fold - 3\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 83ms/step - loss: 10.3364 - acc: 0.5981\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 86ms/step - loss: 10.1264 - acc: 0.5996\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 75ms/step - loss: 10.0613 - acc: 0.5996\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 74ms/step - loss: 10.0198 - acc: 0.5996\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 75ms/step - loss: 10.0073 - acc: 0.5996\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([217,  63,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([361], dtype=int64))\n",
      "accuracy= 0.6011080332409973 precision= [0.60110803 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75086505 0.         0.        ]\n",
      "Fold - 4\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 10s 94ms/step - loss: 10.2608 - acc: 0.5946\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 90ms/step - loss: 10.0917 - acc: 0.5995\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 9s 89ms/step - loss: 10.0984 - acc: 0.5995\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0273 - acc: 0.5995\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 9.9902 - acc: 0.5995\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  81], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([360], dtype=int64))\n",
      "accuracy= 0.6 precision= [0.6 0.  0. ] recall= [1. 0. 0.] F1 Score= [0.75 0.   0.  ]\n",
      "Fold - 5\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.3260 - acc: 0.5945\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.1077 - acc: 0.5986\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 9s 83ms/step - loss: 10.0579 - acc: 0.5986\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 10.0355 - acc: 0.5986\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.0292 - acc: 0.5986\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 6\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.3108 - acc: 0.5954\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 9s 84ms/step - loss: 10.1129 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 9s 87ms/step - loss: 10.0843 - acc: 0.5992\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0506 - acc: 0.5992\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0477 - acc: 0.5992\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 7\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 89ms/step - loss: 10.3360 - acc: 0.5979\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.1132 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0837 - acc: 0.5992\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0273 - acc: 0.5992\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0337 - acc: 0.5992\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 8\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 85ms/step - loss: 10.3262 - acc: 0.5973\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 80ms/step - loss: 10.1042 - acc: 0.5992\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0688 - acc: 0.5992\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0355 - acc: 0.5992\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0145 - acc: 0.5992\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n",
      "Fold - 9\n",
      "Epoch 1/5\n",
      "102/102 [==============================] - 9s 83ms/step - loss: 10.4012 - acc: 0.5915\n",
      "Epoch 2/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.1259 - acc: 0.5980\n",
      "Epoch 3/5\n",
      "102/102 [==============================] - 8s 81ms/step - loss: 10.0948 - acc: 0.5980\n",
      "Epoch 4/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0562 - acc: 0.5980\n",
      "Epoch 5/5\n",
      "102/102 [==============================] - 8s 82ms/step - loss: 10.0128 - acc: 0.5980\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([216,  63,  80], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([359], dtype=int64))\n",
      "accuracy= 0.6016713091922006 precision= [0.60167131 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.75130435 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for index, (train_ind, test_ind) in enumerate(kf.split(X1, yForSk)):\n",
    "    print(\"Fold -\", index)\n",
    "    xtrain, xtest = X1[train_ind], X1[test_ind]\n",
    "    ytrain, ytest = y[train_ind], y[test_ind]\n",
    "    \n",
    "    model = train(xtrain, ytrain)\n",
    "    \n",
    "    predictions = model.predict(xtest)\n",
    "    \n",
    "    y_pred = tf.argmax(predictions, dimension=1)\n",
    "    y_test = tf.argmax(ytest.reshape(len(ytest), 3), dimension=1)\n",
    "    \n",
    "    print(\"Labels=\", np.unique(y_test, return_counts=True))\n",
    "    print(\"Predictions=\", np.unique(y_pred, return_counts=True))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    numer = np.diag(cm)\n",
    "    numer = numer.astype(np.float64)\n",
    "    deno = np.sum(cm, axis = 1, dtype=np.float64)\n",
    "    recall = np.divide(numer, deno, out=np.zeros_like(numer), where=deno!=0)\n",
    "    deno = np.sum(cm, axis = 0, dtype=np.float64)\n",
    "    precision = np.divide(numer, deno, out=np.zeros_like(numer), where=deno!=0)\n",
    "    #loss, acc = model.evaluate(xtest, ytest)\n",
    "    nnum = (precision*recall)\n",
    "    ddeno = (precision+recall)\n",
    "    f1 = 2*np.divide(nnum, ddeno, out=np.zeros_like(nnum), where=ddeno!=0)\n",
    "    acc = np.sum(numer)/np.sum(deno)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    print(\"accuracy=\", acc, \"precision=\", precision, \"recall=\", recall, \"F1 Score=\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Scores:\n",
      "Avg. accuracy= 0.6007807120638463\n",
      "Avg. precision= [0.60078071 0.         0.        ]\n",
      "Avg. recall= [1. 0. 0.]\n",
      "Avg. f1= [0.75060915 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Scores:\")\n",
    "print(\"Avg. accuracy=\", np.sum(accuracies)/len(accuracies))\n",
    "print(\"Avg. precision=\", np.sum(precisions, axis=0)/len(precisions))\n",
    "print(\"Avg. recall=\", np.sum(recalls, axis=0)/len(recalls))\n",
    "print(\"Avg. f1=\", np.sum(f1s, axis=0)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,   0,  78],\n",
       "       [ 59,   0,  33],\n",
       "       [ 83,   0,  91]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.one_hot(tf.argmax(predictions, dimension=1), depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(579), Dimension(3)])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-98b82e0ce3d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#np.zeros(300).shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#word2vec.distances(word2vec['computer'], other_words=[\"laptop\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mword2vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"i5\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "#word2vec['#']#.reshape(300, 1) #numpy array\n",
    "#print(word2vec.similarity('computer', 'laptop'))\n",
    "#np.zeros(300).shape\n",
    "#word2vec.distances(word2vec['computer'], other_words=[\"laptop\"])\n",
    "word2vec[\"i5\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
