{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import string\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable eager execution since this code is experimental\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = str.maketrans('/', ' ', '!\"#$%&\\'()*+,-.:;<=>?@[\\\\]^_`{|}~' + \"0123456789\")\n",
    "table2 = str.maketrans('/', ' ')\n",
    "stopWords = []\n",
    "dataset = []\n",
    "maxSentLen = 0\n",
    "avgSentLen = 0\n",
    "missingVectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as file:\n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        stopWords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text, aspectTerm=None):\n",
    "    text = text.replace(\"[comma]\", \"\")\n",
    "    gw = lambda w: w.lower() if w in aspectTerm else w.translate(table).lower()\n",
    "    if aspectTerm:\n",
    "        text = [gw(word) for word in text.split() \n",
    "                if len(word) > 1 and (word in aspectTerm or word.translate(table).lower() not in stopWords)]        \n",
    "    else:\n",
    "        text = [word.lower() for word in text.translate(table2).split() if len(word) > 1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should $numbers be removed ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 0\n",
    "ll = []\n",
    "with open('data-1_train.csv') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        data = line.split(\",\")\n",
    "        data[2] = preprocess(data[2])\n",
    "        data[1] = preprocess(data[1], data[2])\n",
    "        data[-1] = data[-1].strip()\n",
    "        length += len(data[1])\n",
    "        ll.append(len(data[1]))\n",
    "        if len(data[1]) > maxSentLen:\n",
    "            maxSentLen = len(data[1])\n",
    "        dataset.append(data)\n",
    "avgSentLen = length / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 8.113705144833549\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(maxSentLen, avgSentLen)\n",
    "print(sorted(ll)[int(len(ll)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEOgAkBMEOgDkBIEOADlBoANATvw/koGExwG98FwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20aa040d208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(ll)), sorted(ll))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSentLen = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weD = 300\n",
    "wvD = 2*weD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, label):\n",
    "    inputs = keras.layers.Input(shape=(maxSentLen, wvD, 1))\n",
    "    #print(inputs.shape)\n",
    "\n",
    "    #layer<num>_<filtersize>\n",
    "    conv_layer1_2 = keras.layers.Conv2D(200, (3, wvD), 1, padding='valid', activation=tf.nn.relu)(inputs)\n",
    "    #print(conv_layer1_2.shape)\n",
    "    pool_layer1_2 = keras.layers.MaxPool2D((maxSentLen-3+1, 1), strides=1, padding=\"valid\")(conv_layer1_2)\n",
    "    #print(pool_layer1_2.shape)\n",
    "\n",
    "    conv_layer1_3 = keras.layers.Conv2D(200, (4, wvD), 1, padding='valid', activation=tf.nn.relu)(inputs)\n",
    "    #print(conv_layer1_3.shape)\n",
    "    pool_layer1_3 = keras.layers.MaxPool2D((maxSentLen-4+1, 1), strides=1, padding=\"valid\")(conv_layer1_3)\n",
    "    #print(pool_layer1_3.shape)\n",
    "\n",
    "    conv_layer1_4 = keras.layers.Conv2D(200, (5, wvD), 1, padding='valid', activation=tf.nn.relu)(inputs)\n",
    "    #print(conv_layer1_4.shape)\n",
    "    pool_layer1_4 = keras.layers.MaxPool2D((maxSentLen-5+1, 1), strides=1, padding=\"valid\")(conv_layer1_4)\n",
    "    #print(pool_layer1_4.shape)\n",
    "\n",
    "    layer1 = keras.layers.concatenate([pool_layer1_2, pool_layer1_3, pool_layer1_4], axis=1)\n",
    "    #print(layer1.shape)\n",
    "    layer1 = keras.layers.Flatten()(layer1)\n",
    "    #print(layer1.shape)\n",
    "    \n",
    "    dropout = keras.layers.Dropout(0.5)(layer1)\n",
    "    \n",
    "    out = keras.layers.Dense(3, activation=tf.nn.softmax, kernel_regularizer=keras.regularizers.l2(0.01))(dropout)\n",
    "    #print(out.shape)\n",
    "\n",
    "    nnModel = keras.models.Model(inputs=inputs, outputs=out)\n",
    "    nnModel.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #data = np.array([[word2vec['computer'].reshape(300, 1), word2vec['good'].reshape(300, 1), word2vec['screen'].reshape(300, 1), word2vec['bad'].reshape(300, 1), word2vec['keyboard'].reshape(300, 1)]])\n",
    "    #print(\"data=\", data.shape)\n",
    "    #label = np.array([[1.0, 0.0, 0.0]])\n",
    "    #print(\"label=\", label.shape)\n",
    "    nnModel.fit(data, label, epochs=5)\n",
    "    return nnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = []\n",
    "y = []\n",
    "yForSk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in dataset:\n",
    "    data1 = []\n",
    "    meanAspVec = None\n",
    "    \n",
    "    #if more than one word in aspect term, take mean\n",
    "    mean = np.zeros((weD, 1))\n",
    "    for w in data[2]:\n",
    "        twv = None\n",
    "        try:\n",
    "            if w in missingVectors:\n",
    "                twv = missingVectors[w]\n",
    "            else:\n",
    "                twv = word2vec[w].reshape(weD, 1)\n",
    "        except KeyError:\n",
    "            twv = np.random.normal(size=(weD, 1))/math.sqrt(weD+1)\n",
    "            missingVectors[w] = twv\n",
    "        mean += twv\n",
    "    meanAspVec = mean/len(data[2])\n",
    "    \n",
    "    E = []\n",
    "    \n",
    "#     for wv in data1:\n",
    "#         E.append(np.dot(wv.T, meanAspVec)/(np.linalg.norm(wv)) * np.linalg.norm(meanAspVec))\n",
    "    \n",
    "#     E = np.array(E).reshape(300, 1)\n",
    "#     A = np.exp(E) / np.sum(np.exp(E))\n",
    "\n",
    "    for w in data[1]:\n",
    "        twv = None\n",
    "        try:\n",
    "            if w in missingVectors:\n",
    "                twv = missingVectors[w]\n",
    "            else:\n",
    "                twv = word2vec[w].reshape(weD, 1)\n",
    "        except KeyError:\n",
    "            twv = np.random.normal(size=(weD, 1))/math.sqrt(weD+1)\n",
    "            missingVectors[w] = twv\n",
    "        E.append(np.dot(twv.T, meanAspVec) / (np.linalg.norm(twv) * np.linalg.norm(meanAspVec)))\n",
    "\n",
    "    A = np.exp(E) / np.sum(np.exp(E)) # softmax\n",
    "\n",
    "    for i, w in enumerate(data[1]):\n",
    "        twv = None\n",
    "        if w in missingVectors:\n",
    "            twv = missingVectors[w]\n",
    "        else:\n",
    "            twv = word2vec[w].reshape(weD, 1)\n",
    "        data1.append(np.vstack((twv, A[i] * twv)))\n",
    "\n",
    "#     for w in data[1]:\n",
    "#         twv = None\n",
    "#         try:\n",
    "#             if w in missingVectors:\n",
    "#                 twv = missingVectors[w]\n",
    "#             else:\n",
    "#                 twv = word2vec[w].reshape(300, 1)\n",
    "#         except KeyError:\n",
    "#             twv = np.random.normal(size=(300, 1))/math.sqrt(301)\n",
    "#             missingVectors[w] = twv\n",
    "            \n",
    "#         data1.append(np.vstack((twv, meanAspVec)))\n",
    "    \n",
    "    if len(data1) < maxSentLen:\n",
    "        j = len(data1) + 1\n",
    "        while j <= maxSentLen:\n",
    "            #data1.append(np.vstack((word2vec['#'].reshape(300, 1), meanAspVec)))\n",
    "            #data1.append(np.vstack((np.zeros((300, 1)), meanAspVec)))\n",
    "            data1.append(np.zeros((wvD, 1)))\n",
    "            j += 1\n",
    "    \n",
    "    if len(data1) > maxSentLen:\n",
    "        del data1[maxSentLen:]\n",
    "    \n",
    "    X1.append(np.array(data1))\n",
    "    yForSk.append(data[-1])\n",
    "    if data[-1] == '-1':\n",
    "        y.append(np.array([[0.0, 0.0, 1.0]]))\n",
    "    elif data[-1] == '0':\n",
    "        y.append(np.array([[0.0, 1.0, 0.0]]))\n",
    "    elif data[-1] == '1':\n",
    "        y.append(np.array([[1.0, 0.0, 0.0]]))\n",
    "\n",
    "X1 = np.array(X1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2313, 15, 600, 1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2313, 1, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2313,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yForSk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 0\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 13s 194ms/step - loss: 11.3081 - acc: 0.3954\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 13s 192ms/step - loss: 11.0985 - acc: 0.4194\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 13s 191ms/step - loss: 11.0746 - acc: 0.4243\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 13s 192ms/step - loss: 11.0616 - acc: 0.4226\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 13s 192ms/step - loss: 11.0211 - acc: 0.4424\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 87], dtype=int64))\n",
      "Predictions= (array([0, 1, 2], dtype=int64), array([182,   1,  49], dtype=int64))\n",
      "accuracy= 0.5043103448275862 precision= [0.48351648 1.         0.57142857] recall= [0.88888889 0.02173913 0.32183908] F1 Score= [0.62633452 0.04255319 0.41176471]\n",
      "Fold - 1\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 13s 195ms/step - loss: 11.2342 - acc: 0.3968\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 13s 201ms/step - loss: 11.1412 - acc: 0.4119\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 13s 196ms/step - loss: 11.0890 - acc: 0.4212\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 13s 193ms/step - loss: 11.0421 - acc: 0.4422\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 14s 212ms/step - loss: 11.0362 - acc: 0.4382\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 87], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([231,   1], dtype=int64))\n",
      "accuracy= 0.43103448275862066 precision= [0.42857143 0.         1.        ] recall= [1.         0.         0.01149425] F1 Score= [0.6        0.         0.02272727]\n",
      "Fold - 2\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 13s 197ms/step - loss: 11.1911 - acc: 0.4196\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 13s 191ms/step - loss: 11.1090 - acc: 0.4207\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 13s 191ms/step - loss: 11.0640 - acc: 0.4389\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 16s 237ms/step - loss: 11.0642 - acc: 0.4322\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 13s 195ms/step - loss: 11.0426 - acc: 0.4401\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 87], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([220,  12], dtype=int64))\n",
      "accuracy= 0.44396551724137934 precision= [0.44090909 0.         0.5       ] recall= [0.97979798 0.         0.06896552] F1 Score= [0.60815047 0.         0.12121212]\n",
      "Fold - 3\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 14s 210ms/step - loss: 11.2274 - acc: 0.4087\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 14s 213ms/step - loss: 11.1044 - acc: 0.4199\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 16s 247ms/step - loss: 11.0867 - acc: 0.4193\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 13s 203ms/step - loss: 11.0608 - acc: 0.4368\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 12s 187ms/step - loss: 11.0390 - acc: 0.4358\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 87], dtype=int64))\n",
      "Predictions= (array([0], dtype=int64), array([232], dtype=int64))\n",
      "accuracy= 0.4267241379310345 precision= [0.42672414 0.         0.        ] recall= [1. 0. 0.] F1 Score= [0.59818731 0.         0.        ]\n",
      "Fold - 4\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 12s 186ms/step - loss: 11.2897 - acc: 0.4109\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 14s 207ms/step - loss: 11.1013 - acc: 0.4297\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 14s 210ms/step - loss: 11.0730 - acc: 0.4352\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 14s 212ms/step - loss: 11.0514 - acc: 0.4372\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 15s 222ms/step - loss: 11.0378 - acc: 0.4392\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 87], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([171,  61], dtype=int64))\n",
      "accuracy= 0.44396551724137934 precision= [0.45614035 0.         0.40983607] recall= [0.78787879 0.         0.28735632] F1 Score= [0.57777778 0.         0.33783784]\n",
      "Fold - 5\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 13s 193ms/step - loss: 11.2520 - acc: 0.4011\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 12s 183ms/step - loss: 11.0891 - acc: 0.4213\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 13s 194ms/step - loss: 11.0778 - acc: 0.4266\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 13s 194ms/step - loss: 11.0462 - acc: 0.4223\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 13s 190ms/step - loss: 11.0325 - acc: 0.4317\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 87], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([159,  73], dtype=int64))\n",
      "accuracy= 0.4956896551724138 precision= [0.47798742 0.         0.53424658] recall= [0.76767677 0.         0.44827586] F1 Score= [0.58914729 0.         0.4875    ]\n",
      "Fold - 6\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 13s 195ms/step - loss: 11.2412 - acc: 0.4218\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 14s 209ms/step - loss: 11.1396 - acc: 0.4265\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 13s 192ms/step - loss: 11.0819 - acc: 0.4277\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 13s 193ms/step - loss: 11.0856 - acc: 0.4275\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 13s 204ms/step - loss: 11.0592 - acc: 0.4255\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([99, 46, 86], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([ 71, 160], dtype=int64))\n",
      "accuracy= 0.4675324675324675 precision= [0.54929577 0.         0.43125   ] recall= [0.39393939 0.         0.80232558] F1 Score= [0.45882353 0.         0.56097561]\n",
      "Fold - 7\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 12s 180ms/step - loss: 11.2862 - acc: 0.4172\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 13s 202ms/step - loss: 11.1188 - acc: 0.4224\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 15s 222ms/step - loss: 11.1100 - acc: 0.4319\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 15s 225ms/step - loss: 11.0504 - acc: 0.4374\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 17s 253ms/step - loss: 11.0587 - acc: 0.4293\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([98, 46, 86], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([229,   1], dtype=int64))\n",
      "accuracy= 0.4217391304347826 precision= [0.42358079 0.         0.        ] recall= [0.98979592 0.         0.        ] F1 Score= [0.59327217 0.         0.        ]\n",
      "Fold - 8\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 14s 212ms/step - loss: 11.2403 - acc: 0.4201\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 15s 226ms/step - loss: 11.1582 - acc: 0.4235\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 14s 212ms/step - loss: 11.0837 - acc: 0.4291\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 12s 179ms/step - loss: 11.0637 - acc: 0.4325\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 12s 184ms/step - loss: 11.0648 - acc: 0.4311\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([98, 46, 86], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([222,   8], dtype=int64))\n",
      "accuracy= 0.45217391304347826 precision= [0.44144144 0.         0.75      ] recall= [1.         0.         0.06976744] F1 Score= [0.6125     0.         0.12765957]\n",
      "Fold - 9\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 12s 183ms/step - loss: 11.2431 - acc: 0.4225\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 14s 210ms/step - loss: 11.1102 - acc: 0.4301\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 12s 184ms/step - loss: 11.0877 - acc: 0.4285\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 12s 187ms/step - loss: 11.0905 - acc: 0.4309\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 13s 196ms/step - loss: 11.0566 - acc: 0.4295\n",
      "Labels= (array([0, 1, 2], dtype=int64), array([98, 46, 86], dtype=int64))\n",
      "Predictions= (array([0, 2], dtype=int64), array([207,  23], dtype=int64))\n",
      "accuracy= 0.44782608695652176 precision= [0.43961353 0.         0.52173913] recall= [0.92857143 0.         0.13953488] F1 Score= [0.59672131 0.         0.22018349]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for index, (train_ind, test_ind) in enumerate(kf.split(X1, yForSk)):\n",
    "    print(\"Fold -\", index)\n",
    "    xtrain, xtest = X1[train_ind], X1[test_ind]\n",
    "    ytrain, ytest = y[train_ind], y[test_ind]\n",
    "    \n",
    "    model = train(xtrain, ytrain)\n",
    "    \n",
    "    predictions = model.predict(xtest)\n",
    "    \n",
    "    y_pred = tf.argmax(predictions, dimension=1)\n",
    "    y_test = tf.argmax(ytest.reshape(len(ytest), 3), dimension=1)\n",
    "    \n",
    "    print(\"Labels=\", np.unique(y_test, return_counts=True))\n",
    "    print(\"Predictions=\", np.unique(y_pred, return_counts=True))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    numer = np.diag(cm)\n",
    "    numer = numer.astype(np.float64)\n",
    "    deno = np.sum(cm, axis = 1, dtype=np.float64)\n",
    "    recall = np.divide(numer, deno, out=np.zeros_like(numer), where=deno!=0)\n",
    "    deno = np.sum(cm, axis = 0, dtype=np.float64)\n",
    "    precision = np.divide(numer, deno, out=np.zeros_like(numer), where=deno!=0)\n",
    "    #loss, acc = model.evaluate(xtest, ytest)\n",
    "    nnum = (precision*recall)\n",
    "    ddeno = (precision+recall)\n",
    "    f1 = 2*np.divide(nnum, ddeno, out=np.zeros_like(nnum), where=ddeno!=0)\n",
    "    acc = np.sum(numer)/np.sum(deno)\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    print(\"accuracy=\", acc, \"precision=\", precision, \"recall=\", recall, \"F1 Score=\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Scores:\n",
      "Avg. accuracy= 0.4534961253139664\n",
      "Avg. precision= [0.45677804 0.1        0.47185003]\n",
      "Avg. recall= [0.87365492 0.00217391 0.21495589]\n",
      "Avg. f1= [0.58609144 0.00425532 0.22898606]\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Scores:\")\n",
    "print(\"Avg. accuracy=\", np.sum(accuracies)/len(accuracies))\n",
    "print(\"Avg. precision=\", np.sum(precisions, axis=0)/len(precisions))\n",
    "print(\"Avg. recall=\", np.sum(recalls, axis=0)/len(recalls))\n",
    "print(\"Avg. f1=\", np.sum(f1s, axis=0)/len(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,   0,  78],\n",
       "       [ 59,   0,  33],\n",
       "       [ 83,   0,  91]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.one_hot(tf.argmax(predictions, dimension=1), depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(579), Dimension(3)])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16894531, -0.0480957 , -0.0480957 ,  0.265625  ,  0.02832031,\n",
       "        0.05297852,  0.04370117,  0.28125   ,  0.14160156,  0.32421875,\n",
       "       -0.04931641,  0.02514648,  0.10742188, -0.28515625,  0.19921875,\n",
       "        0.28320312,  0.11132812, -0.09619141, -0.02990723, -0.18457031,\n",
       "       -0.18457031,  0.08203125,  0.09863281,  0.1015625 ,  0.05737305,\n",
       "       -0.05981445, -0.1875    ,  0.34570312, -0.15234375, -0.21289062,\n",
       "        0.20019531,  0.3125    ,  0.03271484, -0.04882812, -0.16992188,\n",
       "       -0.3046875 , -0.14648438,  0.19238281,  0.13378906,  0.28710938,\n",
       "        0.21875   ,  0.26367188,  0.30273438, -0.04614258, -0.12695312,\n",
       "       -0.05615234,  0.10595703, -0.453125  , -0.13476562,  0.09423828,\n",
       "       -0.03833008, -0.16308594, -0.25      ,  0.08935547, -0.07958984,\n",
       "        0.26171875,  0.20703125,  0.02941895,  0.0534668 ,  0.140625  ,\n",
       "        0.08886719,  0.19335938, -0.21875   ,  0.14160156,  0.1953125 ,\n",
       "       -0.20996094,  0.05712891,  0.24511719, -0.27148438,  0.17382812,\n",
       "       -0.01287842, -0.12109375,  0.15722656, -0.10205078, -0.11523438,\n",
       "       -0.34570312,  0.22949219, -0.09521484, -0.24609375, -0.09033203,\n",
       "       -0.14453125,  0.25195312, -0.12255859,  0.00836182,  0.11669922,\n",
       "        0.20605469,  0.40429688,  0.47460938,  0.19824219, -0.11132812,\n",
       "       -0.06103516, -0.12695312, -0.3203125 ,  0.34765625, -0.31835938,\n",
       "        0.28515625, -0.02478027,  0.39257812,  0.01611328,  0.07373047,\n",
       "        0.21191406, -0.03955078,  0.23828125,  0.09912109, -0.18261719,\n",
       "        0.04443359,  0.06640625,  0.28320312,  0.20019531, -0.15039062,\n",
       "        0.07470703, -0.22167969, -0.07177734,  0.12890625, -0.17871094,\n",
       "        0.21484375, -0.20410156, -0.23144531,  0.03955078, -0.30664062,\n",
       "        0.14453125,  0.08642578, -0.21386719, -0.10693359,  0.02819824,\n",
       "        0.00628662, -0.42578125,  0.5       ,  0.06738281,  0.07519531,\n",
       "        0.06591797, -0.22949219, -0.05908203,  0.11132812,  0.03320312,\n",
       "       -0.17382812,  0.08789062, -0.08544922,  0.16992188, -0.26757812,\n",
       "       -0.01507568,  0.02722168,  0.03857422, -0.078125  , -0.07568359,\n",
       "        0.08789062,  0.29296875,  0.10058594, -0.19335938, -0.24902344,\n",
       "        0.16113281, -0.35742188, -0.29101562,  0.05493164,  0.14355469,\n",
       "       -0.14355469, -0.36523438, -0.00335693, -0.11035156, -0.06591797,\n",
       "       -0.15429688,  0.02575684, -0.13378906, -0.21679688,  0.13378906,\n",
       "        0.03735352,  0.01409912,  0.12109375, -0.30078125,  0.11865234,\n",
       "       -0.43945312, -0.16015625, -0.00531006, -0.06396484, -0.546875  ,\n",
       "        0.18066406,  0.45507812, -0.22167969,  0.18261719, -0.14257812,\n",
       "       -0.14355469,  0.07714844,  0.00939941, -0.0859375 , -0.09179688,\n",
       "       -0.22949219,  0.19433594,  0.4140625 , -0.36132812, -0.27929688,\n",
       "       -0.24414062, -0.06152344, -0.29492188, -0.22363281,  0.02294922,\n",
       "        0.13671875,  0.42382812,  0.07861328,  0.08544922, -0.19335938,\n",
       "        0.16894531,  0.20117188,  0.07128906,  0.07666016,  0.1640625 ,\n",
       "       -0.25      ,  0.0222168 , -0.40234375, -0.11767578,  0.20898438,\n",
       "       -0.08447266,  0.17382812, -0.06103516,  0.265625  , -0.15917969,\n",
       "        0.20117188, -0.08447266,  0.45117188, -0.5078125 ,  0.16796875,\n",
       "       -0.21875   ,  0.28125   ,  0.41796875,  0.328125  , -0.12060547,\n",
       "       -0.0625    , -0.33984375,  0.11572266, -0.33984375,  0.01470947,\n",
       "        0.04223633,  0.0703125 ,  0.18457031, -0.50390625, -0.23242188,\n",
       "        0.13769531,  0.09277344,  0.09570312, -0.01184082,  0.15429688,\n",
       "       -0.04980469, -0.08935547, -0.2109375 , -0.30664062,  0.06103516,\n",
       "       -0.6796875 , -0.14355469,  0.43164062, -0.09228516,  0.08398438,\n",
       "        0.01507568,  0.20605469,  0.10791016, -0.15625   ,  0.36328125,\n",
       "       -0.03588867,  0.140625  , -0.06542969, -0.11816406, -0.22265625,\n",
       "        0.29882812,  0.29296875,  0.09277344,  0.07910156,  0.01599121,\n",
       "       -0.22460938,  0.16015625, -0.421875  , -0.14550781, -0.2890625 ,\n",
       "       -0.125     , -0.2265625 , -0.15917969,  0.2421875 ,  0.38085938,\n",
       "        0.18359375,  0.2890625 , -0.35546875, -0.27734375,  0.16992188,\n",
       "        0.1328125 ,  0.0324707 , -0.06298828,  0.23144531,  0.14355469,\n",
       "       -0.13671875, -0.21484375,  0.15722656, -0.0246582 ,  0.10302734,\n",
       "        0.0859375 ,  0.04907227,  0.01831055,  0.14453125,  0.35546875,\n",
       "        0.06933594,  0.10009766,  0.13183594,  0.01623535, -0.125     ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vec['#']#.reshape(300, 1) #numpy array\n",
    "#print(word2vec.similarity('computer', 'laptop'))\n",
    "#np.zeros(300).shape\n",
    "#word2vec.distances(word2vec['computer'], other_words=[\"laptop\"])\n",
    "word2vec[\"i5\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
